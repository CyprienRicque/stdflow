{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c6716273de2753",
   "metadata": {},
   "source": [
    "# Step\n",
    "\n",
    "> Step to load and export and data in an easy and consistent way. is present at notebook level when \n",
    "> `import stdflow as sf` with `stdflow.load(...)` \n",
    "> or wherever you want using the class `step = Step(...)` -> `step.load(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2822a01f966dfd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34accf6b69c7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from __future__ import annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cd99c54116be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d4d9864265baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# isort: off\n",
    "from stdflow.environ_manager import FlowEnv\n",
    "from stdflow.stdflow_doc.documenter import (\n",
    "    Documenter,\n",
    "    CREATE,\n",
    "    IMPORT,\n",
    "    DROP,\n",
    "    ORIGIN_NAME,\n",
    "    ORIGIN_PATH,\n",
    "    NO_DETAILS,\n",
    ")\n",
    "from stdflow.stdflow_utils.caller_metadata import get_caller_metadata, get_notebook_path\n",
    "from stdflow.stdflow_utils.io import load_from_pkl, save_to_pkl\n",
    "\n",
    "# isort: on\n",
    "\n",
    "try:\n",
    "    from typing import Any, Literal, Optional, Tuple, Union, Iterable\n",
    "except ImportError:\n",
    "    from typing_extensions import Literal, Union, Any, Tuple\n",
    "\n",
    "from types import ModuleType\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from stdflow.config import DEFAULT_DATE_VERSION_FORMAT, INFER\n",
    "from stdflow.filemetadata import FileMetaData, get_file, get_file_md\n",
    "from stdflow.stdflow_path import DataPath\n",
    "from stdflow.stdflow_types.strftime_type import Strftime\n",
    "from stdflow.stdflow_utils import export_viz_html, get_arg_value, string_to_uuid\n",
    "\n",
    "from stdflow.stdflow_utils.list_op import filter_list, nested_replace, flatten, alias_from_file_metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3983a4df8ab9bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3807b6a7d5aa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "loaders = dict(\n",
    "    csv=pd.read_csv,\n",
    "    excel=pd.read_excel,\n",
    "    xlsx=pd.read_excel,\n",
    "    xls=pd.read_excel,\n",
    "    parquet=pd.read_parquet,\n",
    "    json=pd.read_json,\n",
    "    pickle=pd.read_pickle,\n",
    "    feather=pd.read_feather,\n",
    "    hdf=pd.read_hdf,\n",
    "    sql=pd.read_sql,\n",
    "    pkl=load_from_pkl,\n",
    ")\n",
    "# full list: [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182cf31ed0dd90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "savers = dict(\n",
    "    csv=pd.DataFrame.to_csv,\n",
    "    excel=pd.DataFrame.to_excel,\n",
    "    xlsx=pd.DataFrame.to_excel,\n",
    "    xls=pd.DataFrame.to_excel,\n",
    "    parquet=pd.DataFrame.to_parquet,\n",
    "    json=pd.DataFrame.to_json,\n",
    "    pickle=pd.DataFrame.to_pickle,\n",
    "    feather=pd.DataFrame.to_feather,\n",
    "    hdf=pd.DataFrame.to_hdf,\n",
    "    sql=pd.DataFrame.to_sql,\n",
    "    pkl=save_to_pkl,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fded495946a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class GStep:\n",
    "    \"\"\"Singleton Step used at package level\"\"\"\n",
    "\n",
    "    _instance = None\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        if not cls._instance:\n",
    "            cls._instance = Step()\n",
    "        return cls._instance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0128e21641ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class Step(ModuleType):\n",
    "    \"Step Class for easy data loading and exporting. Also present at package level\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str | None = \"./data\", # Default root folder of data path. Not exported in metadata\n",
    "        attrs: str | list[str] | None = None, # Default attributes part of the path\n",
    "        version: str | None = \":default\", # Default version name (cannot use :last or other custom variables)\n",
    "        file_name: str | None = \":auto\", # Specify the file name. See file_name_in and file_name_out for more details on :auto behaviour \n",
    "        method_in: str | object | None = \":auto\", # Default method to load the data.  # Method to load the data. Can be a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl].\n",
    "        root_in: str | None = \":default\", # Default root folder when loading [not recommended, use root instead]\n",
    "        attrs_in: str | list[str] | None = \":default\", # Default attributes when loading\n",
    "        step_in: str | None = None, # Default step name when loading\n",
    "        version_in: str | None = \":default\", # Default version name when loading\n",
    "        file_name_in: str | None = \":default\", # Default file name when loading\n",
    "        method_out: str | object | None = \":auto\", # Default method to save the data. Can a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl] \n",
    "        root_out: str | None = \":default\", # Default root folder when saving [not recommended, use root instead]\n",
    "        attrs_out: str | list[str] | None = \":default\", # Default attributes when saving\n",
    "        step_out: str | None = None, # Default step name when saving\n",
    "        version_out: str | None = \":default\", # Default version name when saving\n",
    "        file_name_out: str | None = \":default\", # Default file name when saving\n",
    "        md_all_files: list[FileMetaData] = None, # Internal. Do not use\n",
    "        md_direct_input_files: list[FileMetaData] = None, # Internal. Do not use\n",
    "    ):\n",
    "        \"\"\"Create Step class with default variables later used when doing load and save operations\n",
    "        \n",
    "        at package level, these values can be accessed like\n",
    "        import stdflow as sf\n",
    "        \n",
    "        sf.root = \"./data\"\n",
    "        sf.method_in = \"csv\"\n",
    "        ...\n",
    "        \"\"\"\n",
    "        super().__init__(\"stdflow_step\")\n",
    "\n",
    "        self.env = FlowEnv()\n",
    "\n",
    "        # === Exported === #\n",
    "        # all inputs to this step\n",
    "        self.md_all_files: list[FileMetaData] = md_all_files if md_all_files is not None else []\n",
    "        # direct input to this step\n",
    "        self.md_direct_input_files: list[FileMetaData] = (\n",
    "            md_direct_input_files if md_direct_input_files is not None else []\n",
    "        )\n",
    "        # ================ #\n",
    "\n",
    "        # Default values of load and save functions\n",
    "        self._method_in = method_in\n",
    "        self._root_in = root_in\n",
    "        self._attrs_in = attrs_in\n",
    "        self._step_in = step_in\n",
    "        self._version_in = version_in\n",
    "        self._file_name_in = file_name_in\n",
    "\n",
    "        self._method_out = method_out\n",
    "        self._root_out = root_out\n",
    "        self._attrs_out = attrs_out\n",
    "        self._step_out = step_out\n",
    "        self._version_out = version_out\n",
    "        self._file_name_out = file_name_out\n",
    "\n",
    "        self._root = root\n",
    "        self._version = version\n",
    "        self._attrs = attrs\n",
    "        self._file_name = file_name\n",
    "\n",
    "        # Used when actually using the step to save the variables set\n",
    "        self._var_set = {}\n",
    "\n",
    "        self.doc = Documenter()\n",
    "\n",
    "    def set_defaults(  # TODO some are not implemented\n",
    "        self,\n",
    "        *,\n",
    "        root: str | None = \"./data\",\n",
    "        attrs: str | list[str] | None = None,\n",
    "        version: str | None = \":default\",\n",
    "        file_name: str | None = \":auto\",\n",
    "        method_in: str | object | None = \":auto\",\n",
    "        root_in: str | None = \":default\",\n",
    "        attrs_in: str | list[str] | None = \":default\",\n",
    "        step_in: str | None = None,\n",
    "        version_in: str | None = \":default\",\n",
    "        file_name_in: str | None = \":default\",\n",
    "        method_out: str | object | None = \":auto\",\n",
    "        root_out: str | None = \":default\",\n",
    "        attrs_out: str | list[str] | None = \":default\",\n",
    "        step_out: str | None = None,\n",
    "        version_out: str | None = DEFAULT_DATE_VERSION_FORMAT,\n",
    "        file_name_out: str | None = \":default\",\n",
    "    ):\n",
    "        self._root = root\n",
    "        self._attrs = attrs\n",
    "        self._version = version\n",
    "        self._file_name = file_name\n",
    "\n",
    "        self._method_in = method_in\n",
    "        self._root_in = root_in\n",
    "        self._attrs_in = attrs_in\n",
    "        self._step_in = step_in\n",
    "        self._version_in = version_in\n",
    "        self._file_name_in = file_name_in\n",
    "\n",
    "        self._method_out = method_out\n",
    "        self._root_out = root_out\n",
    "        self._attrs_out = attrs_out\n",
    "        self._step_out = step_out\n",
    "        self._version_out = version_out\n",
    "        self._file_name_out = file_name_out\n",
    "\n",
    "    def var(self, key, value, force=False):\n",
    "        \"Set a variable which can be overwritten if specified in StepRunner / Pipeline\"\n",
    "        env_var = self.env.var(key)\n",
    "\n",
    "        if env_var is not None and not force:\n",
    "            logger.debug(f\"using {key} from environment variable\")\n",
    "            return env_var\n",
    "        self._var_set[key] = value\n",
    "        return value\n",
    "\n",
    "    def col_step(\n",
    "        self,\n",
    "        col: str,\n",
    "        name: str,\n",
    "        in_cols: pd.Index | pd.Series | list | str | None = None,\n",
    "        alias: str = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        syntactic sugar to document a column\n",
    "        \"\"\"\n",
    "        self.doc.document(col, name, in_cols=in_cols, alias=alias)\n",
    "\n",
    "    def create_col(self, col, comment: str = NO_DETAILS, alias: str = None):\n",
    "        \"\"\"\n",
    "        syntactic sugar to document a column creation\n",
    "        \"\"\"\n",
    "        self.doc.document(col, name=CREATE + comment, alias=alias, in_cols=[])\n",
    "\n",
    "    def import_col(self, col, comment: str = NO_DETAILS, alias: str = None):\n",
    "        \"\"\"\n",
    "        syntactic sugar to document a column import\n",
    "        \"\"\"\n",
    "        self.doc.document(col, name=IMPORT + comment, alias=alias, in_cols=[])\n",
    "\n",
    "    def drop_col(self, col, comment: str = NO_DETAILS, alias: str = None):\n",
    "        \"\"\"\n",
    "        syntactic sugar to document a column drop\n",
    "        \"\"\"\n",
    "        self.doc.document(col, name=DROP + comment, alias=alias, in_cols=[])\n",
    "\n",
    "    def col_origin_name(\n",
    "        self,\n",
    "        col: str,\n",
    "        origin_name: str,\n",
    "        in_cols: str | Iterable | Literal[\":auto\"] = \":auto\",\n",
    "        alias: str | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param col:\n",
    "        :param origin_name:\n",
    "        :param in_cols: default to the same as col\n",
    "        :param alias:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if in_cols == \":auto\":\n",
    "            in_cols = col\n",
    "        self.doc.document(col, ORIGIN_NAME + origin_name, in_cols=in_cols, alias=alias)\n",
    "\n",
    "    def col_origin_path(\n",
    "        self,\n",
    "        col: str,\n",
    "        origin_path: str,\n",
    "        in_cols: str | Iterable | Literal[\":auto\"] = \":auto\",\n",
    "        alias: str | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param col:\n",
    "        :param origin_path:\n",
    "        :param in_cols: default to the same as col\n",
    "        :param alias:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if in_cols == \":auto\":\n",
    "            in_cols = col\n",
    "        self.doc.document(col, ORIGIN_PATH + origin_path, in_cols=in_cols, alias=alias)\n",
    "\n",
    "    def cols_step(\n",
    "        self, cols: list, col_step: str, input_cols: pd.Index | pd.Series | list | str | None = None\n",
    "    ):\n",
    "        for col in cols:\n",
    "            self.col_step(col, col_step, in_cols=input_cols)\n",
    "\n",
    "    def cols_steps(\n",
    "        self, cols_steps: dict, input_cols: pd.Index | pd.Series | list | str | None = None\n",
    "    ):\n",
    "        for col, col_step in cols_steps.items():\n",
    "            self.col_step(col, col_step, in_cols=input_cols)\n",
    "\n",
    "    def get_doc(self, col: str, alias: str | None = None, starts_with: str | None = None):\n",
    "        col_steps = self.doc.get_documentation(col, alias)\n",
    "        if starts_with is None:\n",
    "            return col_steps\n",
    "        return filter_list(col_steps, starts_with)\n",
    "\n",
    "    def get_origin_names_raw(self, col: str, alias: str):\n",
    "        return self.get_doc(col, alias, ORIGIN_NAME)\n",
    "\n",
    "    def get_origin_names(self, col: str, alias: str):\n",
    "        return nested_replace(flatten(self.get_doc(col, alias, ORIGIN_NAME)), ORIGIN_NAME, \"\")\n",
    "\n",
    "    def load(\n",
    "        self, \n",
    "        root: str | Literal[\":default\"] = \":default\", # Root folder of the data. Not exported in metadata\n",
    "        attrs: list | str | None | Literal[\":default\"] = \":default\", # Attributes part of the path\n",
    "        step: str | None | Literal[\":default\"] = \":default\", # Step name, converted to step_{step_name} in the path\n",
    "        version: str | None | Literal[\":default\", \":last\", \":first\"] = \":default\", # Version name, converted to v_{version_name} in the path. if :default, uses :last, if :last uses last version based on its name. if :first, uses first version based on its name\n",
    "        file_name: str | Literal[\":default\", \":auto\"] = \":default\", # File name. automatically inferred if there is only one file in the directory\n",
    "        method: str | object | Literal[\":default\", \":auto\"] = \":default\", # Method to load the data. Can be a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl].\n",
    "        alias: str = \":ignore\", # Alias of the dataset to document it and its columns. (feature in development)\n",
    "        file_glob: bool = False, # If True, file_name can be a glob pattern\n",
    "        verbose: bool = False, # If True, print info messages\n",
    "        **kwargs, # Parameters for the loading funtion\n",
    "    ) -> Tuple[Any, dict] | Any: # Loaded data\n",
    "        \"\"\"\n",
    "        Load data with path such as\n",
    "        root/*attrs/step/version/file_name\n",
    "        \"\"\"\n",
    "        \n",
    "        original_logger_level = logger.level\n",
    "        logger.setLevel(logging.INFO if verbose else logging.WARNING)\n",
    "\n",
    "        # DEBUG prints\n",
    "        caller_file_name, caller_function, caller_package = get_caller_metadata()\n",
    "        if \"ipykernel\" in caller_file_name:\n",
    "            notebook_path, notebook_name = get_notebook_path()\n",
    "            logger.debug(f\"Called from jupyter notebook {notebook_name} in {notebook_path}\")\n",
    "        elif caller_function == \"<module>\":\n",
    "            logger.debug(f\"Called from python file {caller_file_name}\")\n",
    "        else:\n",
    "            logger.debug(f\"Called from function {caller_function} in {caller_file_name}\")\n",
    "\n",
    "        logger.debug(f\"caller_metadata: {caller_file_name, caller_function, caller_package}\")\n",
    "        # END DEBUG prints\n",
    "\n",
    "        # if arguments are None, use step level arguments\n",
    "        root = get_arg_value(get_arg_value(root, self._root_in), self._root)\n",
    "        attrs = get_arg_value(get_arg_value(attrs, self._attrs_in), self._attrs)\n",
    "        file_name = get_arg_value(get_arg_value(file_name, self._file_name_in), self._file_name)\n",
    "        step = get_arg_value(step, self._step_in)\n",
    "        version = get_arg_value(get_arg_value(get_arg_value(version, self._version_in), self._version), \":last\")\n",
    "        method = get_arg_value(method, self._method_in)\n",
    "\n",
    "        # if self.env.running() and root is None:\n",
    "        #     raise ValueError(\"root is None. Must be set when running from pipeline\")\n",
    "        # if root is not None:\n",
    "        #     root = self.env.get_adjusted_worker_path(root)\n",
    "\n",
    "        path: DataPath = DataPath.from_input_params(\n",
    "            root, attrs, step, version, file_name, glob=file_glob\n",
    "        )\n",
    "        if not path.file_name:\n",
    "            raise ValueError(f\"file_name is None. path: {path}\")\n",
    "\n",
    "        if method == \":auto\":\n",
    "            method = path.extension\n",
    "        if isinstance(method, str):\n",
    "            if method not in loaders:\n",
    "                raise ValueError(f\"method {method} not in {list(loaders.keys())}\")\n",
    "            method = loaders[method]\n",
    "\n",
    "        # Load data\n",
    "        logger.info(f\"Loading data from {path.full_path}\")\n",
    "        data = method(path.full_path, **kwargs)\n",
    "        logger.info(f\"Data loaded from {path.full_path}\")\n",
    "\n",
    "        # Add metadata\n",
    "        previous_step: Step = Step._from_path(path)\n",
    "\n",
    "        def fake_step():\n",
    "            previous_step_ = Step()\n",
    "            previous_step_.md_all_files = [FileMetaData.from_data(path, data)]\n",
    "            if alias != \":ignore\":\n",
    "                for md in previous_step_.md_all_files:\n",
    "                    previous_step_.doc.set_dataframe(\n",
    "                        columns=[c[\"name\"] for c in md.columns],\n",
    "                        col_steps=md.col_steps,\n",
    "                        alias=\"tmp\",\n",
    "                    )\n",
    "            return previous_step_\n",
    "\n",
    "        def update_current_step_with_previous_step(previous_step_):\n",
    "            file_md_: FileMetaData = get_file_md(previous_step_.md_all_files, path)\n",
    "            if file_md_:\n",
    "                input_files_ = previous_step_._files_needed_to_gen([file_md_]) + [file_md_]\n",
    "            else:  # The file is not in the metadata file\n",
    "                warnings.warn(\n",
    "                    f\"metadata file found but file {path.full_path} not present in it.\"\n",
    "                    f\"Quick fix: change the file location as it was not generated the same way as other files\"\n",
    "                    f\"in this folder. current behavior: Using the file as having no previous step \"\n",
    "                    f\"and ignoring the metadata file.\",\n",
    "                    category=UserWarning,\n",
    "                )\n",
    "                return None, None\n",
    "            return file_md_, input_files_\n",
    "\n",
    "        file_md: FileMetaData = None\n",
    "        input_files = None\n",
    "        if previous_step is not None:\n",
    "            file_md, input_files = update_current_step_with_previous_step(previous_step)\n",
    "        if input_files is None:\n",
    "            previous_step = fake_step()\n",
    "            file_md, input_files = update_current_step_with_previous_step(previous_step)\n",
    "\n",
    "        # do not add the same file twice in self.data_l\n",
    "        # 1. Keep the file one if same uuid\n",
    "        # 2. Add if same path but different uuid: same file twice but with different timestamps (error from the dev)\n",
    "        for input_file in input_files:\n",
    "            if input_file not in [f for f in self.md_all_files]:  # file already added: same uuid\n",
    "                self.md_all_files.append(input_file)\n",
    "\n",
    "        # file loaded\n",
    "        if file_md not in [f for f in self.md_direct_input_files]:  # file already added: same uuid\n",
    "            self.md_direct_input_files.append(file_md)\n",
    "\n",
    "        # Update documentation\n",
    "        if alias != \":ignore\":\n",
    "            alias = alias or alias_from_file_metadata(file_md)\n",
    "\n",
    "            self.doc.set_dataframe(\n",
    "                columns=[c[\"name\"] for c in file_md.columns],\n",
    "                col_steps=file_md.col_steps,\n",
    "                alias=alias,\n",
    "            )\n",
    "\n",
    "        logger.setLevel(original_logger_level)\n",
    "        return data\n",
    "\n",
    "    def save(\n",
    "        self, \n",
    "        data: pd.DataFrame | Any, # data to save\n",
    "        root: str | Literal[\":default\"] = \":default\", # Root folder of the data. Not exported in metadata\n",
    "        attrs: list | str | None | Literal[\":default\"] = \":default\", # Attributes part of the path\n",
    "        step: str | None | Literal[\":default\"] = \":default\", # Step name, converted to step_{step_name} in the path\n",
    "        version: str | None | Literal[\":default\"] | Strftime = \":default\", # Version name, converted to v_{version_name} in the path. by default uses the current date in format %Y%m%d%H%M\n",
    "        file_name: str | Literal[\":default\", \":auto\"] = \":default\", # File name. automatically inferred if there is only one input file \n",
    "        method: str | object | Literal[\":default\", \":auto\"] = \":default\", # Method to save the data. Can a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl]. If function, the first argument must be the path\n",
    "        alias: str = \":ignore\", # Alias of the dataset to document it and its columns. (feature in development)\n",
    "        export_viz_tool: bool = False, # If True, export html view of the data and the pipeline it comes from\n",
    "        verbose: bool = False, # If True, print info messages\n",
    "        **kwargs, # Parameters for the exporting funtion (e.g. index=False for to_csv)\n",
    "    ) -> DataPath: # Path object describing where the data is saved\n",
    "        \"\"\"\n",
    "        Save data with path such as\n",
    "        root/attrs/step/version/file_name\n",
    "        \"\"\"\n",
    "        original_logger_level = logger.level\n",
    "        logger.setLevel(logging.INFO if verbose else logging.WARNING)\n",
    "\n",
    "        # if arguments are None, use step level arguments\n",
    "        root = get_arg_value(get_arg_value(root, self._root_out), self._root)\n",
    "        attrs = get_arg_value(get_arg_value(attrs, self._attrs_out), self._attrs)\n",
    "        step = get_arg_value(step, self._step_out)\n",
    "        version = get_arg_value(get_arg_value(get_arg_value(version, self._version_out), self._version), DEFAULT_DATE_VERSION_FORMAT)\n",
    "        file = get_arg_value(get_arg_value(file_name, self._file_name_out), self._file_name)\n",
    "        method = get_arg_value(method, self._method_out)\n",
    "\n",
    "        if Strftime.__call__(version):\n",
    "            version = datetime.now().strftime(version)\n",
    "\n",
    "        if file == \":auto\":\n",
    "            # Use the same file name as the one use to create it\n",
    "            # Should be only file in self.data_l_in. take its file name\n",
    "            if len(self.md_direct_input_files) == 1:\n",
    "                file = self.md_direct_input_files[0].path.file_name\n",
    "            elif len(self.md_direct_input_files) > 1:\n",
    "                raise ValueError(\n",
    "                    f\":auto takes the file name of the data source used to create the file.\\n\"\n",
    "                    f\"Multiple data sources detected: {self.md_direct_input_files}\\n\"\n",
    "                    f\"Use file_name argument to specify the file name.\"\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\":auto takes the file name of the data source used to create the file.\"\n",
    "                    f\"No data source detected. Use file_name argument to specify the file name.\"\n",
    "                )\n",
    "\n",
    "        path: DataPath = DataPath.from_input_params(root, attrs, step, version, file)\n",
    "        if not path.file_name:\n",
    "            raise ValueError(f\"file_name is None. path: {path}\")\n",
    "\n",
    "        # if the directory does not exist, create it recursively\n",
    "        if not os.path.exists(path.dir_path):\n",
    "            os.makedirs(path.dir_path)\n",
    "\n",
    "        if method == \":auto\":\n",
    "            method = path.extension\n",
    "        if isinstance(method, str):\n",
    "            if method not in savers:\n",
    "                raise ValueError(f\"method {method} not in {list(savers.keys())}\")\n",
    "            method = savers[method]\n",
    "\n",
    "        # Save data\n",
    "        logger.info(f\"Saving data to {path.full_path}\")\n",
    "        method(data, path.full_path, **kwargs)\n",
    "        logger.info(f\"Data saved to {path.full_path}\")\n",
    "\n",
    "        saved_file_md = FileMetaData.from_data(\n",
    "            path, data, method.__str__(), self.md_direct_input_files\n",
    "        )\n",
    "\n",
    "        if alias != \":ignore\":\n",
    "            self.columns_documentation(alias, data, path, saved_file_md)\n",
    "\n",
    "        self.md_all_files.append(saved_file_md)\n",
    "\n",
    "        # export metadata file\n",
    "        logger.info(f\"Saving metadata to {path.dir_path}\")\n",
    "        self._to_file(path)\n",
    "\n",
    "        if export_viz_tool:\n",
    "            logger.info(f\"Exporting viz tool to {path.dir_path}\")\n",
    "            export_viz_html(path.metadata_path, path.dir_path)\n",
    "\n",
    "        logger.setLevel(original_logger_level)\n",
    "\n",
    "        return path\n",
    "\n",
    "    def columns_documentation(\n",
    "        self, alias: str | None, data: Any, path: DataPath, saved_file_md: FileMetaData\n",
    "    ) -> None:\n",
    "        # FIXME step col should be at file level\n",
    "\n",
    "        if alias == \":ignore\":\n",
    "            return\n",
    "\n",
    "        # automatic input file detection\n",
    "        if alias is None:\n",
    "            # md_direct_input_files with same file name and attrs\n",
    "            input_file = [\n",
    "                file\n",
    "                for file in self.md_direct_input_files\n",
    "                if file.path.attrs == path.attrs and file.path.file_name == path.file_name\n",
    "            ]\n",
    "\n",
    "            # find initial loaded file\n",
    "            if len(self.md_direct_input_files) == 1:\n",
    "                alias = alias_from_file_metadata(self.md_direct_input_files[0])\n",
    "            elif len(input_file) == 1:\n",
    "                alias = alias_from_file_metadata(input_file[0])\n",
    "            elif len(self.md_direct_input_files) == 0:\n",
    "                alias = alias_from_file_metadata(saved_file_md)\n",
    "            else:\n",
    "                logger.warning(\n",
    "                    f\"Could not auto save cols documentation:\"\n",
    "                    f\":auto takes the file name of the data source used to create the file.\\n\"\n",
    "                    f\"Multiple data sources detected: {self.md_direct_input_files}\\n\"\n",
    "                    f\"Use alias argument to specify the datasource to use. or set alias=':ignore'\"\n",
    "                )\n",
    "\n",
    "        if alias is not None:\n",
    "            saved_file_md.col_steps = self.doc.metadata(data, alias)\n",
    "\n",
    "    def reset(self):\n",
    "        # === Exported === #\n",
    "        self.md_all_files: list[FileMetaData] = []\n",
    "        self.md_direct_input_files: list[FileMetaData] = []  # direct input to this step file\n",
    "        # ================ #\n",
    "\n",
    "        # Default values of load and save functions\n",
    "        self.set_defaults()\n",
    "\n",
    "        # reset documentation\n",
    "        self.doc.reset()\n",
    "\n",
    "    # === Private === #\n",
    "\n",
    "    def __dict__(self):\n",
    "        return dict(\n",
    "            files=[d.__dict__() for d in self.md_all_files],\n",
    "        )\n",
    "\n",
    "    def _files_needed_to_gen(self, files_to_gen: list[FileMetaData]) -> list[FileMetaData]:\n",
    "        \"\"\"\n",
    "        Risk of infinite loop if there is a cycle in the graph TODO\n",
    "        :param files_to_gen:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        def get_input_files(files: list[FileMetaData]) -> list[str]:\n",
    "            uuids = list(\n",
    "                {item[\"uuid\"] for sublist in [e.input_files for e in files] for item in sublist}\n",
    "            )\n",
    "\n",
    "            if not len(uuids):\n",
    "                return []\n",
    "            return uuids + get_input_files([e for e in self.md_all_files if e.uuid in uuids])\n",
    "\n",
    "        # recursive\n",
    "        input_files = get_input_files(files_to_gen)\n",
    "        return [e for e in self.md_all_files if e.uuid in input_files]\n",
    "\n",
    "    @classmethod\n",
    "    def _from_dict(cls, d):  # TODO clean\n",
    "        \"\"\"\n",
    "        The detection of generated files only works because all files not generated by the export step are input files\n",
    "        of other files. This in ensured by loading only files that are input of used files to this step.\n",
    "        :param d:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        step = cls()\n",
    "        step.md_all_files = [FileMetaData.from_dict(e) for e in d[\"files\"]]\n",
    "        # data_l_in are input_files of files that are never used as input_files\n",
    "        input_files = {\n",
    "            item[\"uuid\"]\n",
    "            for sublist in [e.input_files for e in step.md_all_files]\n",
    "            for item in sublist\n",
    "        }\n",
    "        generated_files = [e for e in step.md_all_files if e.uuid not in input_files]\n",
    "        step.md_direct_input_files = list(\n",
    "            {\n",
    "                item[\"uuid\"]\n",
    "                for sublist in [e.input_files for e in generated_files]\n",
    "                for item in sublist\n",
    "            }\n",
    "        )\n",
    "        step.md_direct_input_files = [\n",
    "            e for e in step.md_all_files if e.uuid in step.md_direct_input_files\n",
    "        ]  # useless?\n",
    "        return step\n",
    "\n",
    "    @classmethod\n",
    "    def _from_file(cls, path):\n",
    "        \"\"\"\n",
    "        tries to load json meta data file, if no file, returns None\n",
    "        :param path:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if not os.path.exists(path):\n",
    "            logger.debug(f\"no metadata file found in {path}\")\n",
    "            return None\n",
    "        return cls._from_dict(json.load(open(path, \"r\")))\n",
    "\n",
    "    @classmethod\n",
    "    def _from_path(cls, path: DataPath):\n",
    "        return Step._from_file(path.metadata_path)\n",
    "\n",
    "    def _to_file(self, path: DataPath):\n",
    "        \"\"\"Save step to file\"\"\"\n",
    "        file_path = os.path.join(path.dir_path, FileMetaData.file_name)\n",
    "        if not os.path.exists(path.dir_path):\n",
    "            os.makedirs(path.dir_path)\n",
    "        if os.path.exists(file_path):\n",
    "            logger.debug(f\"metadata file already exists in {file_path}. Replacing\")\n",
    "        with open(file_path, \"w\") as f:\n",
    "            logger.debug(f\"Saving metadata file to {file_path}\")\n",
    "            # logger.debug(f\"metadata: {self.__dict__()}\")\n",
    "            json.dump(self.__dict__(), f)\n",
    "\n",
    "    # === Properties === #\n",
    "\n",
    "    @property\n",
    "    def step_in(self) -> str:\n",
    "        return self._step_in\n",
    "\n",
    "    @step_in.setter\n",
    "    def step_in(self, step_name: str) -> None:\n",
    "        self._step_in = step_name\n",
    "\n",
    "    @property\n",
    "    def version_in(self) -> str:\n",
    "        return self._version_in\n",
    "\n",
    "    @version_in.setter\n",
    "    def version_in(self, version_name: str) -> None:\n",
    "        self._version_in = version_name\n",
    "\n",
    "    @property\n",
    "    def version(self) -> str:\n",
    "        return self._version\n",
    "\n",
    "    @version.setter\n",
    "    def version(self, version_name: str) -> None:\n",
    "        self._version = version_name\n",
    "\n",
    "    @property\n",
    "    def attrs_in(self) -> list | str:\n",
    "        return self._attrs_in\n",
    "\n",
    "    @attrs_in.setter\n",
    "    def attrs_in(self, attrs: list | str) -> None:\n",
    "        self._attrs_in = attrs\n",
    "\n",
    "    @property\n",
    "    def file_name_in(self) -> str:\n",
    "        return self._file_name_in\n",
    "\n",
    "    @file_name_in.setter\n",
    "    def file_name_in(self, file_name: str) -> None:\n",
    "        self._file_name_in = file_name\n",
    "\n",
    "    @property\n",
    "    def method_in(self) -> str | object:\n",
    "        return self._method_in\n",
    "\n",
    "    @method_in.setter\n",
    "    def method_in(self, method: str | object) -> None:\n",
    "        self._method_in = method\n",
    "\n",
    "    @property\n",
    "    def root_in(self) -> str:\n",
    "        return self._root_in\n",
    "\n",
    "    @root_in.setter\n",
    "    def root_in(self, root: str) -> None:\n",
    "        self._root_in = root\n",
    "\n",
    "    @property\n",
    "    def step_out(self) -> str:\n",
    "        return self._step_out\n",
    "\n",
    "    @step_out.setter\n",
    "    def step_out(self, step_name: str) -> None:\n",
    "        self._step_out = step_name\n",
    "\n",
    "    @property\n",
    "    def version_out(self) -> str:\n",
    "        return self._version_out\n",
    "\n",
    "    @version_out.setter\n",
    "    def version_out(self, version_name: str) -> None:\n",
    "        self._version_out = version_name\n",
    "\n",
    "    @property\n",
    "    def attrs_out(self) -> list | str:\n",
    "        return self._attrs_out\n",
    "\n",
    "    @attrs_out.setter\n",
    "    def attrs_out(self, attrs: list | str) -> None:\n",
    "        self._attrs_out = attrs\n",
    "\n",
    "    @property\n",
    "    def file_name_out(self) -> str:\n",
    "        return self._file_name_out\n",
    "\n",
    "    @file_name_out.setter\n",
    "    def file_name_out(self, file_name: str) -> None:\n",
    "        self._file_name_out = file_name\n",
    "\n",
    "    @property\n",
    "    def method_out(self) -> str | object:\n",
    "        return self._method_out\n",
    "\n",
    "    @method_out.setter\n",
    "    def method_out(self, method: str | object) -> None:\n",
    "        self._method_out = method\n",
    "\n",
    "    @property\n",
    "    def root_out(self) -> str:\n",
    "        return self._root_out\n",
    "\n",
    "    @root_out.setter\n",
    "    def root_out(self, root: str) -> None:\n",
    "        self._root_out = root\n",
    "\n",
    "    @property\n",
    "    def root(self) -> str:\n",
    "        return self._root\n",
    "\n",
    "    @root.setter\n",
    "    def root(self, root: str) -> None:\n",
    "        self._root = root\n",
    "\n",
    "    @property\n",
    "    def file_name(self) -> str:\n",
    "        return self._file_name\n",
    "\n",
    "    @file_name.setter\n",
    "    def file_name(self, file_name: str) -> None:\n",
    "        self._file_name = file_name\n",
    "\n",
    "    @property\n",
    "    def attrs(self) -> list | str:\n",
    "        return self._attrs\n",
    "\n",
    "    @attrs.setter\n",
    "    def attrs(self, attrs: list | str) -> None:\n",
    "        self._attrs = attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c475d002eb9ef40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/CyprienRicque/stdflow/blob/main/stdflow/step.py#L309){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Step.load\n",
       "\n",
       ">      Step.load\n",
       ">                 (root:Union[str,typing_extensions.Literal[':default']]=':defau\n",
       ">                 lt', attrs:Union[list,str,NoneType,typing_extensions.Literal['\n",
       ">                 :default']]=':default', step:Union[str,NoneType,typing_extensi\n",
       ">                 ons.Literal[':default']]=':default', version:Union[str,NoneTyp\n",
       ">                 e,typing_extensions.Literal[':default',':last',':first']]=':de\n",
       ">                 fault', file_name:Union[str,typing_extensions.Literal[':defaul\n",
       ">                 t',':auto']]=':default', method:Union[str,object,typing_extens\n",
       ">                 ions.Literal[':default',':auto']]=':default',\n",
       ">                 alias:str=':ignore', file_glob:bool=False, verbose:bool=False,\n",
       ">                 **kwargs)\n",
       "\n",
       "Load data with path such as\n",
       "root/*attrs/step/version/file_name\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| root | str \\| Literal[':default'] | :default | Root folder of the data. Not exported in metadata |\n",
       "| attrs | list \\| str \\| None \\| Literal[':default'] | :default | Attributes part of the path |\n",
       "| step | str \\| None \\| Literal[':default'] | :default | Step name, converted to step_{step_name} in the path |\n",
       "| version | str \\| None \\| Literal[(':default', ':last', ':first')] | :default | Version name, converted to v_{version_name} in the path. if :default, uses :last, if :last uses last version based on its name. if :first, uses first version based on its name |\n",
       "| file_name | str \\| Literal[(':default', ':auto')] | :default | File name. automatically inferred if there is only one file in the directory |\n",
       "| method | str \\| object \\| Literal[(':default', ':auto')] | :default | Method to load the data. Can be a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl]. |\n",
       "| alias | str | :ignore | Alias of the dataset to document it and its columns. (feature in development) |\n",
       "| file_glob | bool | False | If True, file_name can be a glob pattern |\n",
       "| verbose | bool | False | If True, print info messages |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **Tuple[Any, dict] \\| Any** |  | **Loaded data** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/CyprienRicque/stdflow/blob/main/stdflow/step.py#L309){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Step.load\n",
       "\n",
       ">      Step.load\n",
       ">                 (root:Union[str,typing_extensions.Literal[':default']]=':defau\n",
       ">                 lt', attrs:Union[list,str,NoneType,typing_extensions.Literal['\n",
       ">                 :default']]=':default', step:Union[str,NoneType,typing_extensi\n",
       ">                 ons.Literal[':default']]=':default', version:Union[str,NoneTyp\n",
       ">                 e,typing_extensions.Literal[':default',':last',':first']]=':de\n",
       ">                 fault', file_name:Union[str,typing_extensions.Literal[':defaul\n",
       ">                 t',':auto']]=':default', method:Union[str,object,typing_extens\n",
       ">                 ions.Literal[':default',':auto']]=':default',\n",
       ">                 alias:str=':ignore', file_glob:bool=False, verbose:bool=False,\n",
       ">                 **kwargs)\n",
       "\n",
       "Load data with path such as\n",
       "root/*attrs/step/version/file_name\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| root | str \\| Literal[':default'] | :default | Root folder of the data. Not exported in metadata |\n",
       "| attrs | list \\| str \\| None \\| Literal[':default'] | :default | Attributes part of the path |\n",
       "| step | str \\| None \\| Literal[':default'] | :default | Step name, converted to step_{step_name} in the path |\n",
       "| version | str \\| None \\| Literal[(':default', ':last', ':first')] | :default | Version name, converted to v_{version_name} in the path. if :default, uses :last, if :last uses last version based on its name. if :first, uses first version based on its name |\n",
       "| file_name | str \\| Literal[(':default', ':auto')] | :default | File name. automatically inferred if there is only one file in the directory |\n",
       "| method | str \\| object \\| Literal[(':default', ':auto')] | :default | Method to load the data. Can be a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl]. |\n",
       "| alias | str | :ignore | Alias of the dataset to document it and its columns. (feature in development) |\n",
       "| file_glob | bool | False | If True, file_name can be a glob pattern |\n",
       "| verbose | bool | False | If True, print info messages |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **Tuple[Any, dict] \\| Any** |  | **Loaded data** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "show_doc(Step.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df486df10ed7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/CyprienRicque/stdflow/blob/main/stdflow/step.py#L436){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Step.save\n",
       "\n",
       ">      Step.save (data:Union[pandas.core.frame.DataFrame,typing_extensions.Any],\n",
       ">                 root:Union[str,typing_extensions.Literal[':default']]=':defaul\n",
       ">                 t', attrs:Union[list,str,NoneType,typing_extensions.Literal[':\n",
       ">                 default']]=':default', step:Union[str,NoneType,typing_extensio\n",
       ">                 ns.Literal[':default']]=':default', version:Union[str,NoneType\n",
       ">                 ,typing_extensions.Literal[':default'],stdflow.stdflow_types.s\n",
       ">                 trftime_type.Strftime]=':default', file_name:Union[str,typing_\n",
       ">                 extensions.Literal[':default',':auto']]=':default', method:Uni\n",
       ">                 on[str,object,typing_extensions.Literal[':default',':auto']]='\n",
       ">                 :default', alias:str=':ignore', export_viz_tool:bool=False,\n",
       ">                 verbose:bool=False, **kwargs)\n",
       "\n",
       "Save data with path such as\n",
       "root/attrs/step/version/file_name\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | pd.DataFrame \\| Any |  | data to save |\n",
       "| root | str \\| Literal[':default'] | :default | Root folder of the data. Not exported in metadata |\n",
       "| attrs | list \\| str \\| None \\| Literal[':default'] | :default | Attributes part of the path |\n",
       "| step | str \\| None \\| Literal[':default'] | :default | Step name, converted to step_{step_name} in the path |\n",
       "| version | str \\| None \\| Literal[':default'] \\| Strftime | :default | Version name, converted to v_{version_name} in the path. by default uses the current date in format %Y%m%d%H%M |\n",
       "| file_name | str \\| Literal[(':default', ':auto')] | :default | File name. automatically inferred if there is only one input file |\n",
       "| method | str \\| object \\| Literal[(':default', ':auto')] | :default | Method to save the data. Can a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl]. If function, the first argument must be the path |\n",
       "| alias | str | :ignore | Alias of the dataset to document it and its columns. (feature in development) |\n",
       "| export_viz_tool | bool | False | If True, export html view of the data and the pipeline it comes from |\n",
       "| verbose | bool | False | If True, print info messages |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **DataPath** |  | **Path object describing where the data is saved** |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/CyprienRicque/stdflow/blob/main/stdflow/step.py#L436){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Step.save\n",
       "\n",
       ">      Step.save (data:Union[pandas.core.frame.DataFrame,typing_extensions.Any],\n",
       ">                 root:Union[str,typing_extensions.Literal[':default']]=':defaul\n",
       ">                 t', attrs:Union[list,str,NoneType,typing_extensions.Literal[':\n",
       ">                 default']]=':default', step:Union[str,NoneType,typing_extensio\n",
       ">                 ns.Literal[':default']]=':default', version:Union[str,NoneType\n",
       ">                 ,typing_extensions.Literal[':default'],stdflow.stdflow_types.s\n",
       ">                 trftime_type.Strftime]=':default', file_name:Union[str,typing_\n",
       ">                 extensions.Literal[':default',':auto']]=':default', method:Uni\n",
       ">                 on[str,object,typing_extensions.Literal[':default',':auto']]='\n",
       ">                 :default', alias:str=':ignore', export_viz_tool:bool=False,\n",
       ">                 verbose:bool=False, **kwargs)\n",
       "\n",
       "Save data with path such as\n",
       "root/attrs/step/version/file_name\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| data | pd.DataFrame \\| Any |  | data to save |\n",
       "| root | str \\| Literal[':default'] | :default | Root folder of the data. Not exported in metadata |\n",
       "| attrs | list \\| str \\| None \\| Literal[':default'] | :default | Attributes part of the path |\n",
       "| step | str \\| None \\| Literal[':default'] | :default | Step name, converted to step_{step_name} in the path |\n",
       "| version | str \\| None \\| Literal[':default'] \\| Strftime | :default | Version name, converted to v_{version_name} in the path. by default uses the current date in format %Y%m%d%H%M |\n",
       "| file_name | str \\| Literal[(':default', ':auto')] | :default | File name. automatically inferred if there is only one input file |\n",
       "| method | str \\| object \\| Literal[(':default', ':auto')] | :default | Method to save the data. Can a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl]. If function, the first argument must be the path |\n",
       "| alias | str | :ignore | Alias of the dataset to document it and its columns. (feature in development) |\n",
       "| export_viz_tool | bool | False | If True, export html view of the data and the pipeline it comes from |\n",
       "| verbose | bool | False | If True, print info messages |\n",
       "| kwargs |  |  |  |\n",
       "| **Returns** | **DataPath** |  | **Path object describing where the data is saved** |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "show_doc(Step.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3aa90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/CyprienRicque/stdflow/blob/main/stdflow/step.py#L209){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Step.var\n",
       "\n",
       ">      Step.var (key, value, force=False)\n",
       "\n",
       "Set a variable which can be overwritten if specified in StepRunner / Pipeline"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/CyprienRicque/stdflow/blob/main/stdflow/step.py#L209){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### Step.var\n",
       "\n",
       ">      Step.var (key, value, force=False)\n",
       "\n",
       "Set a variable which can be overwritten if specified in StepRunner / Pipeline"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "show_doc(Step.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e864db12fbd4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
