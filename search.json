[
  {
    "objectID": "step_runner.html",
    "href": "step_runner.html",
    "title": "StepRunner",
    "section": "",
    "text": "source\n\nStepRunner\n\n StepRunner (file_path:str, workspace:str|None=None,\n             function:str|None=None, variables:dict[str,Any]|None=None)\n\nenvironment variables set by stdflow: stdflow__run: if set, the step is executed from a pipeline run stdflow__run__files_path: names of the files executed split by : stdflow__run__ids: ids of the files executed split by : stdflow__run__function_name: name of the function executed stdflow__vars: variables used to run the function\n\nsource\n\n\nStepRunner.run\n\n StepRunner.run (save_notebook:bool=False, kernel:Union[Literal[':current'\n                 ,':target',':any_available'],str]=':target',\n                 kernels_on_fail:Union[list,str]=None, verbose:bool=True,\n                 **kwargs)\n\nRun the function of the pipeline :arg: kernel: kernel name to use or :current to use the current kernel :target to use the kernel in the metadata of the target notebook, :any_available to use any available kernel :arg: kernels_on_fail: list of kernels to try if the kernel specified in kernel fails :arg: save_notebook (bool): whether to save the notebook after execution :arg: verbose (bool): whether to print information about the execution :return: str: message about the execution\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsave_notebook\nbool\nFalse\nSaves the output of cells in the notebook if True (default: False)\n\n\nkernel\nLiteral[‘:current’, ‘:target’, ‘:any_available’] | str\n:target\nkernel name or :current to use current kernel, :target to use kernel specified in metadata of target notebook, :any_available to use any available kernel.\n\n\nkernels_on_fail\nlist | str\nNone\nkernels to try if kernel does not exist / is not available (default: [“:current”, “python”, “:any_available”])\n\n\nverbose\nbool\nTrue\n\n\n\nkwargs\n\n\n\n\n\nReturns\nstr"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "stdflow",
    "section": "",
    "text": "Data flow tool that transform your notebooks and python files into pipeline steps by standardizing the data input / output. (for data science projects)\nCreate clean data flow pipelines just by replacing your pd.read_csv() and df.to_csv() by sf.load() and sf.save().\nDocumentation"
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "stdflow",
    "section": "Install",
    "text": "Install\npip install stdflow"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "stdflow",
    "section": "How to use",
    "text": "How to use\n\nPipelines\n\nfrom stdflow import StepRunner\nfrom stdflow.pipeline import Pipeline\n\n# Pipeline with 2 steps\n\ndm = \"../demo_project/notebooks/\"\n\ningestion_ppl = Pipeline([\n    StepRunner(dm + \"01_ingestion/countries.ipynb\"), \n    StepRunner(dm + \"01_ingestion/world_happiness.ipynb\")\n])\n\n# === OR ===\ningestion_ppl = Pipeline(\n    StepRunner(dm + \"01_ingestion/countries.ipynb\"), \n    StepRunner(dm + \"01_ingestion/world_happiness.ipynb\")\n)\n\n# === OR ===\ningestion_ppl = Pipeline()\n\ningestion_ppl.add_step(StepRunner(dm + \"01_ingestion/countries.ipynb\"))\n# OR\ningestion_ppl.add_step(dm + \"01_ingestion/world_happiness.ipynb\")\n\n\ningestion_ppl\n\n\n\n================================\n            PIPELINE            \n================================\n\nSTEP 1\n    path: ../demo_project/notebooks/01_ingestion/countries.ipynb\n    vars: {}\n\nSTEP 2\n    path: ../demo_project/notebooks/01_ingestion/world_happiness.ipynb\n    vars: {}\n\n================================\n\n\n\nRun the pipeline\n\ningestion_ppl.run(verbose=True, kernel=\":any_available\")\n\n=================================================================================\n    01.                ../demo_project/notebooks/01_ingestion/countries.ipynb\n=================================================================================\nVariables: {}\nusing kernel:  python3\n    Path: ../demo_project/notebooks/01_ingestion/countries.ipynb\n    Duration: 0 days 00:00:00.603051\n    Env: {}\nNotebook executed successfully.\n\n\n=================================================================================\n    02.          ../demo_project/notebooks/01_ingestion/world_happiness.ipynb\n=================================================================================\nVariables: {}\nusing kernel:  python3\n    Path: ../demo_project/notebooks/01_ingestion/world_happiness.ipynb\n    Duration: 0 days 00:00:00.644909\n    Env: {}\nNotebook executed successfully."
  },
  {
    "objectID": "index.html#load-and-save-data",
    "href": "index.html#load-and-save-data",
    "title": "stdflow",
    "section": "Load and save data",
    "text": "Load and save data\n\nOption 1: Specify All Parameters\n\nimport stdflow as sf\nimport pandas as pd\n\n\n# load data from ../demo_project/data/countries/step_loaded/v_202309212245/countries.csv\ndf = sf.load(\n   root=\"../demo_project/data/\",\n   attrs=['countries'],\n   step='created',\n   version=':last',  # loads last version in alphanumeric order\n   file_name='countries.csv',\n   method=pd.read_csv,  # or method='csv'\n   verbose=False,\n)\n\n# export data to ./data/raw/twitter/france/step_processed/v_1/countries.csv\nsf.save(\n   df,\n   root=\"../demo_project/data/\",\n   attrs='countries/',\n   step='loaded',\n   version='%Y-03',  # creates v_2023-03\n   file_name='countries.csv',\n   method=pd.DataFrame.to_csv,  # or method='csv'  or any function that takes the object to export as first input\n)\n\nattrs=countries/::step_name=loaded::version=2023-03::file_name=countries.csv\n\n\nEach time you perform a save, a metadata.json file is created in the folder. This keeps track of how your data was created and other information.\n\n\nOption 2: Use default variables\n\nimport stdflow as sf\nsf.reset()  # used when multiple steps are done with the same Step object (not recommended). see below\n\n# use package level default values\nsf.root = \"../demo_project/data/\"\nsf.attrs = 'countries'  # if needed use attrs_in and attrs_out\nsf.step_in = 'loaded'\nsf.step_out = 'formatted'\n\ndf = sf.load()\n# ! root / attrs / step : used from default values set above\n# ! version : the last version was automatically used. default: \":last\"\n# ! file_name : the file, alone in the folder, was automatically found\n# ! method : was automatically used from the file extension\n\nsf.save(df)\n# ! root / attrs / step : used from default values set above\n# ! version: used default %Y%m%d%H%M format\n# ! file_name: used from the input (because only one file)\n# ! method : inferred from file name\n\nattrs=countries::step_name=formatted::version=202310101716::file_name=countries.csv\n\n\nNote that everything we did at package level can be done with the Step class When you have multiple steps in a notebook, you can create one Step object per step. stdflow (sf) at package level is a singleton instance of Step.\n\nfrom stdflow import Step\n\nstep = Step(\n    root=\"../demo_project/data/\",\n    attrs='countries',\n    step_in='formatted',\n    step_out='pre_processed'\n)\n# or set after\nstep.root = \"../demo_project/data/\"\n# ...\n\ndf = step.load(version=':last', file_name=\":auto\", verbose=True)\n\nstep.save(df, verbose=True)\n\nINFO:stdflow.step:Loading data from ../demo_project/data/countries/step_formatted/v_202310101716/countries.csv\nINFO:stdflow.step:Data loaded from ../demo_project/data/countries/step_formatted/v_202310101716/countries.csv\nINFO:stdflow.step:Saving data to ../demo_project/data/countries/step_pre_processed/v_202310101716/countries.csv\nINFO:stdflow.step:Data saved to ../demo_project/data/countries/step_pre_processed/v_202310101716/countries.csv\nINFO:stdflow.step:Saving metadata to ../demo_project/data/countries/step_pre_processed/v_202310101716/\n\n\nattrs=countries::step_name=pre_processed::version=202310101716::file_name=countries.csv\n\n\nEach time you perform a save, a metadata.json file is created in the folder. This keeps track of how your data was created and other information."
  },
  {
    "objectID": "index.html#do-not",
    "href": "index.html#do-not",
    "title": "stdflow",
    "section": "Do not",
    "text": "Do not\n\nSave in the same directory from different steps. Because this will erase metadata from the previous step."
  },
  {
    "objectID": "index.html#data-visualization",
    "href": "index.html#data-visualization",
    "title": "stdflow",
    "section": "Data visualization",
    "text": "Data visualization\n\nimport stdflow as sf\n\nstep.save(df, verbose=True, export_viz_tool=True)\n\nINFO:stdflow.step:Saving data to ../demo_project/data/countries/step_pre_processed/v_202310101716/countries.csv\nINFO:stdflow.step:Data saved to ../demo_project/data/countries/step_pre_processed/v_202310101716/countries.csv\nINFO:stdflow.step:Saving metadata to ../demo_project/data/countries/step_pre_processed/v_202310101716/\nINFO:stdflow.step:Exporting viz tool to ../demo_project/data/countries/step_pre_processed/v_202310101716/\n\n\nattrs=countries::step_name=pre_processed::version=202310101716::file_name=countries.csv\n\n\nThis command exports a folder metadata_viz in the same folder as the data you exported. The metadata to display is saved in the metadata.json file.\nIn order to display it you need to get both the file and the folder on your local pc (download if you are working on a server)\nThen go to the html file in your file explorer and open it. it should open in your browser and lets you upload the metadata.json file.\nData flow tool that transform your notebooks and python files into pipeline steps by standardizing the data input / output. (for data science projects)\nCreate clean data flow pipelines just by replacing your pd.read_csv() and df.to_csv() by sf.load() and sf.save()."
  },
  {
    "objectID": "index.html#data-organization",
    "href": "index.html#data-organization",
    "title": "stdflow",
    "section": "Data Organization",
    "text": "Data Organization\n\nFormat\nData folder organization is systematic and used by the function to load and save. If follows this format: root_data_folder/attrs_1/attrs_2/…/attrs_n/step_name/version/file_name\nwhere:\n\nroot_data_folder: is the path to the root of your data folder, and is not exported in the metadata\nattrs: information to classify your dataset (e.g. country, client, …)\nstep_name: name of the step. always starts with step_\nversion: version of the step. always starts with v_\nfile_name: name of the file. can be anything\n\nEach folder is the output of a step. It contains a metadata.json file with information about all files in the folder and how it was generated. It can also contain a html page (if you set html_export=True in save()) that lets you visualize the pipeline and your metadata"
  },
  {
    "objectID": "index.html#best-practices",
    "href": "index.html#best-practices",
    "title": "stdflow",
    "section": "Best Practices:",
    "text": "Best Practices:\n\nDo not use sf.reset as part of your final code\nIn one step, export only to one path (except the version). meaning for one step only one combination of attrs and step_name\nDo not set sub-dirs within the export (i.e. version folder is the last depth). if you need similar operation for different datasets, create pipelines"
  },
  {
    "objectID": "step.html",
    "href": "step.html",
    "title": "Step",
    "section": "",
    "text": "source\n\nGStep\n\n GStep (*args, **kwargs)\n\nSingleton Step used at package level\n\nsource\n\n\nStep\n\n Step (root:str|None='./data', attrs:str|list[str]|None=None,\n       version:str|None=':default', file_name:str|None=':auto',\n       method_in:str|object|None=':auto', root_in:str|None=':default',\n       attrs_in:str|list[str]|None=':default', step_in:str|None=None,\n       version_in:str|None=':default', file_name_in:str|None=':default',\n       method_out:str|object|None=':auto', root_out:str|None=':default',\n       attrs_out:str|list[str]|None=':default', step_out:str|None=None,\n       version_out:str|None=':default', file_name_out:str|None=':default',\n       md_all_files:list[FileMetaData]=None,\n       md_direct_input_files:list[FileMetaData]=None)\n\nStep Class for easy data loading and exporting. Also present at package level\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nroot\nstr | None\n./data\nDefault root folder of data path. Not exported in metadata\n\n\nattrs\nstr | list[str] | None\nNone\nDefault attributes part of the path\n\n\nversion\nstr | None\n:default\nDefault version name (cannot use :last or other custom variables)\n\n\nfile_name\nstr | None\n:auto\nSpecify the file name. See file_name_in and file_name_out for more details on :auto behaviour\n\n\nmethod_in\nstr | object | None\n:auto\nDefault method to load the data. # Method to load the data. Can be a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl].\n\n\nroot_in\nstr | None\n:default\nDefault root folder when loading [not recommended, use root instead]\n\n\nattrs_in\nstr | list[str] | None\n:default\nDefault attributes when loading\n\n\nstep_in\nstr | None\nNone\nDefault step name when loading\n\n\nversion_in\nstr | None\n:default\nDefault version name when loading\n\n\nfile_name_in\nstr | None\n:default\nDefault file name when loading\n\n\nmethod_out\nstr | object | None\n:auto\nDefault method to save the data. Can a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl]\n\n\nroot_out\nstr | None\n:default\nDefault root folder when saving [not recommended, use root instead]\n\n\nattrs_out\nstr | list[str] | None\n:default\nDefault attributes when saving\n\n\nstep_out\nstr | None\nNone\nDefault step name when saving\n\n\nversion_out\nstr | None\n:default\nDefault version name when saving\n\n\nfile_name_out\nstr | None\n:default\nDefault file name when saving\n\n\nmd_all_files\nlist[FileMetaData]\nNone\nInternal. Do not use\n\n\nmd_direct_input_files\nlist[FileMetaData]\nNone\nInternal. Do not use\n\n\n\n\nsource\n\n\nStep.load\n\n Step.load (root:Union[str,Literal[':default']]=':default',\n            attrs:Union[list,str,NoneType,Literal[':default']]=':default',\n            step:Union[str,NoneType,Literal[':default']]=':default', versi\n            on:Union[str,NoneType,Literal[':default',':last',':first']]=':\n            default',\n            file_name:Union[str,Literal[':default',':auto']]=':default', m\n            ethod:Union[str,object,Literal[':default',':auto']]=':default'\n            , alias:str=':ignore', file_glob:bool=False,\n            verbose:bool=False, **kwargs)\n\nLoad data with path such as root/*attrs/step/version/file_name\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nroot\nstr | Literal[‘:default’]\n:default\nRoot folder of the data. Not exported in metadata\n\n\nattrs\nlist | str | None | Literal[‘:default’]\n:default\nAttributes part of the path\n\n\nstep\nstr | None | Literal[‘:default’]\n:default\nStep name, converted to step_{step_name} in the path\n\n\nversion\nstr | None | Literal[‘:default’, ‘:last’, ‘:first’]\n:default\nVersion name, converted to v_{version_name} in the path. if :default, uses :last, if :last uses last version based on its name. if :first, uses first version based on its name\n\n\nfile_name\nstr | Literal[‘:default’, ‘:auto’]\n:default\nFile name. automatically inferred if there is only one file in the directory\n\n\nmethod\nstr | object | Literal[‘:default’, ‘:auto’]\n:default\nMethod to load the data. Can be a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl].\n\n\nalias\nstr\n:ignore\nAlias of the dataset to document it and its columns. (feature in development)\n\n\nfile_glob\nbool\nFalse\nIf True, file_name can be a glob pattern\n\n\nverbose\nbool\nFalse\nIf True, print info messages\n\n\nkwargs\n\n\n\n\n\nReturns\nTuple[Any, dict] | Any\n\nLoaded data\n\n\n\n\nsource\n\n\nStep.save\n\n Step.save (data:Union[pandas.core.frame.DataFrame,Any],\n            root:Union[str,Literal[':default']]=':default',\n            attrs:Union[list,str,NoneType,Literal[':default']]=':default',\n            step:Union[str,NoneType,Literal[':default']]=':default', versi\n            on:Union[str,NoneType,Literal[':default'],stdflow.stdflow_type\n            s.strftime_type.Strftime]=':default',\n            file_name:Union[str,Literal[':default',':auto']]=':default', m\n            ethod:Union[str,object,Literal[':default',':auto']]=':default'\n            , alias:str=':ignore', export_viz_tool:bool=False,\n            verbose:bool=False, **kwargs)\n\nSave data with path such as root/attrs/step/version/file_name\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\npd.DataFrame | Any\n\ndata to save\n\n\nroot\nstr | Literal[‘:default’]\n:default\nRoot folder of the data. Not exported in metadata\n\n\nattrs\nlist | str | None | Literal[‘:default’]\n:default\nAttributes part of the path\n\n\nstep\nstr | None | Literal[‘:default’]\n:default\nStep name, converted to step_{step_name} in the path\n\n\nversion\nstr | None | Literal[‘:default’] | Strftime\n:default\nVersion name, converted to v_{version_name} in the path. by default uses the current date in format %Y%m%d%H%M\n\n\nfile_name\nstr | Literal[‘:default’, ‘:auto’]\n:default\nFile name. automatically inferred if there is only one input file\n\n\nmethod\nstr | object | Literal[‘:default’, ‘:auto’]\n:default\nMethod to save the data. Can a function with path as first argument or a string among [csv, excel, xlsx, xls, parquet, json, pickle, feather, hdf, sql, pkl]. If function, the first argument must be the path\n\n\nalias\nstr\n:ignore\nAlias of the dataset to document it and its columns. (feature in development)\n\n\nexport_viz_tool\nbool\nFalse\nIf True, export html view of the data and the pipeline it comes from\n\n\nverbose\nbool\nFalse\nIf True, print info messages\n\n\nkwargs\n\n\n\n\n\nReturns\nDataPath\n\nPath object describing where the data is saved\n\n\n\n\nsource\n\n\nStep.var\n\n Step.var (key, value, force=False)\n\nSet a variable which can be overwritten if specified in StepRunner / Pipeline\n\nstep.save(\n    df,\n    root=\"../demo_project/data\",\n    attrs=\"lake\",\n    file_name=\"countries of the world.csv\",\n    version=\":default\",\n    method=\"csv\",\n    verbose=True,\n)\n\nsf.root = ../demo_project/data\nsf.attrs = lake\nsf.step = None\nsf.version = %Y%m%d%H%M\nsf.file_name = countries of the world.csv\nsf.method = csv\nSaving data to ../demo_project/data/lake/v_202310121113/countries of the world.csv\n\n\nattrs=lake::step_name=None::version=202310121113::file_name=countries of the world.csv"
  },
  {
    "objectID": "pipeline.html",
    "href": "pipeline.html",
    "title": "Pipeline",
    "section": "",
    "text": "source\n\nPipeline\n\n Pipeline (steps:List[StepRunner]|StepRunner=None, *args)\n\nCreate pipeline of notebooks with optional variables\n\nsource\n\n\nPipeline.add_step\n\n Pipeline.add_step (step:Union[stdflow.step_runner.StepRunner,str]=None,\n                    **kwargs)\n\nAdd step to pipeline\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstep\nStepRunner | str\nNone\nStepRunner or path to notebook\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nPipeline.verify\n\n Pipeline.verify ()\n\nVerify that all steps are valid\n\nsource\n\n\nPipeline.run\n\n Pipeline.run (save_notebook:bool=False, progress_bar:bool=False, kernel:U\n               nion[Literal[':current',':target',':any_available'],str]=':\n               target', kernels_on_fail:Union[str,list]=None,\n               verbose=True, **kwargs)\n\nRun pipeline\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsave_notebook\nbool\nFalse\nSaves the output of cells in the notebook if True (default: False)\n\n\nprogress_bar\nbool\nFalse\nWhether to show progress bar\n\n\nkernel\nLiteral[‘:current’, ‘:target’, ‘:any_available’] | str\n:target\nkernel name or :current to use current kernel, :target to use kernel specified in metadata of target notebook, :any_available to use any available kernel.\n\n\nkernels_on_fail\nstr | list\nNone\nkernels to try if kernel does not exist / is not available (default: [“:current”, “python”, “:any_available”])\n\n\nverbose\nbool\nTrue\nWhether to print output of cells\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nPipeline.__call__\n\n Pipeline.__call__ (progress_bar:bool=False, **kwargs)\n\nRun pipeline\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nprogress_bar\nbool\nFalse\nWhether to show progress bar\n\n\nkwargs"
  }
]